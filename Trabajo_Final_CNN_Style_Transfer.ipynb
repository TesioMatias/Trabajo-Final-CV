{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qCY6UbkkI9_N"
   },
   "source": [
    "# Style Transfer\n",
    "\n",
    "<img src=\"https://i0.wp.com/chelseatroy.com/wp-content/uploads/2018/12/neural_style_transfer.png?resize=768%2C311&ssl=1\">\n",
    "\n",
    "La idea de este trabajo final es reproducir el siguiente paper:\n",
    "\n",
    "https://arxiv.org/pdf/1508.06576.pdf\n",
    "\n",
    "El objetivo es transferir el estilo de una imagen dada a otra imagen distinta. \n",
    "\n",
    "Como hemos visto en clase, las primeras capas de una red convolucional se activan ante la presencia de ciertos patrones vinculados a detalles muy pequeños.\n",
    "\n",
    "A medida que avanzamos en las distintas capas de una red neuronal convolucional, los filtros se van activando a medida que detectan patrones de formas cada vez mas complejos.\n",
    "\n",
    "Lo que propone este paper es asignarle a la activación de las primeras capas de una red neuronal convolucional (por ejemplo VGG19) la definición del estilo y a la activación de las últimas capas de la red neuronal convolucional, la definición del contenido.\n",
    "\n",
    "La idea de este paper es, a partir de dos imágenes (una que aporte el estilo y otra que aporte el contenido) analizar cómo es la activación de las primeras capas para la imagen que aporta el estilo y cómo es la activación de las últimas capas de la red convolucional para la imagen que aporta el contenido. A partir de esto se intentará sintetizar una imagen que active los filtros de las primeras capas que se activaron con la imagen que aporta el estilo y los filtros de las últimas capas que se activaron con la imagen que aporta el contenido.\n",
    "\n",
    "A este procedimiento se lo denomina neural style transfer.\n",
    "\n",
    "# En este trabajo se deberá leer el paper mencionado y en base a ello, entender la implementación que se muestra a continuación y contestar preguntas sobre la misma.\n",
    "\n",
    "# Una metodología posible es hacer una lectura rápida del paper (aunque esto signifique no entender algunos detalles del mismo) y luego ir analizando el código y respondiendo las preguntas. A medida que se planteen las preguntas, volviendo a leer secciones específicas del paper terminará de entender los detalles que pudieran haber quedado pendientes.\n",
    "\n",
    "Lo primero que haremos es cargar dos imágenes, una que aporte el estilo y otra que aporte el contenido. A tal fin utilizaremos imágenes disponibles en la web."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 437
    },
    "id": "kyHsa2t0SxZi",
    "outputId": "e72fcf52-62ed-42f1-f64e-cdb05d049797"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: wget\n",
      "zsh:1: command not found: wget\n",
      "mkdir: /content: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# Imagen para estilo\n",
    "!wget https://upload.wikimedia.org/wikipedia/commons/5/52/La_noche_estrellada1.jpg\n",
    "\n",
    "# Imagen para contenido\n",
    "!wget https://upload.wikimedia.org/wikipedia/commons/thumb/f/f4/Neckarfront_T%C3%BCbingen_Mai_2017.jpg/775px-Neckarfront_T%C3%BCbingen_Mai_2017.jpg\n",
    "\n",
    "# Creamos el directorio para los archivos de salida\n",
    "!mkdir /content/output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 83
    },
    "id": "NIxH20o2eFoc",
    "outputId": "4785bcbb-4070-4e68-c2b5-4a1dfdccbad2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import load_img, save_img, img_to_array\n",
    "import numpy as np\n",
    "from scipy.optimize import fmin_l_bfgs_b\n",
    "import time\n",
    "import argparse\n",
    "\n",
    "from keras.applications import vgg19\n",
    "from keras import backend as K\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "iLkV1bnFl_tK"
   },
   "outputs": [],
   "source": [
    "# Definimos las imagenes que vamos a utilizar, y el directorio de salida\n",
    "\n",
    "base_image_path = Path(\"./content/Neckarfront_Tübingen_Mai_2017.jpg\")\n",
    "style_reference_image_path = Path(\"./content/La_noche_estrellada1.jpg\")\n",
    "result_prefix = Path(\"./content/output\")\n",
    "iterations = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gz2PeGfpeYzj"
   },
   "source": [
    "# 1) En base a lo visto en el paper ¿Qué significan los parámetros definidos en la siguiente celda?\n",
    "\n",
    "Respuesta:\n",
    "\n",
    "En el algoritmo del paper se propone que la loss este compuesta por dos partes. Una de ellas siendo la loss correspondiente al contenido de la una de las imagenes y la otra al estilo de la otra imagen. Tambien dentro de esta loss general se agregan factores mediante los cuales se puede pesar cuanta importante (peso) se le da a cada una de dichas losses (contenido y estilo).\n",
    "Estos valores \"style_weight\" y \"content_weight\", refieren al peso que tendrá cada parte de la loss, en este caso, la loss del estilo tendrá mayor peso que la del contenido.\n",
    "\n",
    "Por otro lado, \"total_variation_weight\" pesa la loss  del placeholder (imagen con ruido) que tomará el estilo y los contenidos de las dos imagnes iniciales (ESTA PARTE NO LA ENTIENDO BIEN; PREGUNTARLO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "P9Dt3aaEmJWS"
   },
   "outputs": [],
   "source": [
    "total_variation_weight = 0.1\n",
    "style_weight = 10\n",
    "content_weight = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "CQQJOhCVuse6"
   },
   "outputs": [],
   "source": [
    "# Definimos el tamaño de las imágenes a utilizar\n",
    "width, height = load_img(base_image_path).size\n",
    "img_nrows = 400\n",
    "img_ncols = int(width * img_nrows / height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gg2ct-8agm1E"
   },
   "source": [
    "# 2) Explicar qué hace la siguiente celda. En especial las últimas dos líneas de la función antes del return. ¿Por qué?\n",
    "\n",
    "Ayuda: https://keras.io/applications/\n",
    "\n",
    "Respuesta:\n",
    "\n",
    "*- concepto general:*\n",
    "\n",
    "El proposito general es preprocesar la imagen para que este en el formato correcto para que pueda procesarse por al red VGG19\n",
    "(por ejemplo cargar la imagen, convertirla en un numpy array, pasarla a BGR y centrar cada canal de color en 0).\n",
    "\n",
    "*- load_img:*\n",
    "\n",
    "Carga la imagen que del \"image_path\", con el size dato por \"img_nrows\" e \"img_ncols\" y devuelve una instancia de la imagen en formato Python Imaging Library\n",
    "\n",
    "*- img_to_array:*\n",
    "\n",
    "Toma una imagen en formato PIL (python imaging library) y la convierte en un numpy array de 3 dimensiones (alto, ancho y RGB)\n",
    "\n",
    "*- np.expand_dims:*\n",
    "\n",
    "Agrega un nuevo axis en la posicion indicada, en este caso en axis = 0 (osea, fila)\n",
    "\n",
    "*- vgg19.preprocess_input:*\n",
    "\n",
    "Preprocesa el numpy array de la imagen obtenida y la convierte de RGB a BGR, luego cada uno de los canales respectivos a cada color es centrado en 0 para que sean acordes a los datasets y forma de entremaniento de VGG19 con ImageNet.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "tAkljg4zuzYd"
   },
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "    img = load_img(image_path, target_size=(img_nrows, img_ncols))\n",
    "    img = img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = vgg19.preprocess_input(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KTf0YDSagt10"
   },
   "source": [
    "# 3) Habiendo comprendido lo que hace la celda anterior, explique de manera muy concisa qué hace la siguiente celda. ¿Qué relación tiene con la celda anterior?\n",
    "\n",
    "Respuesta:\n",
    "\n",
    "Esta funcion quita el axis que se agrego para el procesamiento, dejando un formato normal de imagen,\n",
    "tambien descentra los canales de media 0 a una media dada por cada canal de color y luego modifica la imagend e BGR a RGB.\n",
    "\n",
    "Hace esto para volver del formato que necesita VGG19 al formato standard de imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "y5LaTrsAu14z"
   },
   "outputs": [],
   "source": [
    "def deprocess_image(x):\n",
    "    x = x.reshape((img_nrows, img_ncols, 3))\n",
    "    # Remove zero-center by mean pixel\n",
    "    x[:, :, 0] += 103.939\n",
    "    x[:, :, 1] += 116.779\n",
    "    x[:, :, 2] += 123.68\n",
    "    # 'BGR'->'RGB'\n",
    "    x = x[:, :, ::-1]\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "HYNio09mu4S3"
   },
   "outputs": [],
   "source": [
    "# get tensor representations of our images\n",
    "# K.variable convierte un numpy array en un tensor, para \n",
    "base_image = K.variable(preprocess_image(base_image_path))\n",
    "style_reference_image = K.variable(preprocess_image(style_reference_image_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "a1Lbw02Uu--o",
    "outputId": "6cc926fa-55af-43fa-fe91-3b68c0910502"
   },
   "outputs": [],
   "source": [
    "combination_image = K.placeholder((1, img_nrows, img_ncols, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RJEi0YI3Uzrm"
   },
   "source": [
    "Aclaración:\n",
    "\n",
    "La siguiente celda sirve para procesar las tres imagenes (contenido, estilo y salida) en un solo batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "gGO_jGFfvEbF"
   },
   "outputs": [],
   "source": [
    "# combine the 3 images into a single Keras tensor\n",
    "input_tensor = K.concatenate([base_image,\n",
    "                              style_reference_image,\n",
    "                              combination_image], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "tdG59VRavHGB",
    "outputId": "a133befb-68d1-4c51-99e6-417c1103f726"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "80142336/80134624 [==============================] - 3s 0us/step\n",
      "Model loaded.\n"
     ]
    }
   ],
   "source": [
    "# build the VGG19 network with our 3 images as input\n",
    "# the model will be loaded with pre-trained ImageNet weights\n",
    "model = vgg19.VGG19(input_tensor=input_tensor,\n",
    "                    weights='imagenet', include_top=False)\n",
    "print('Model loaded.')\n",
    "\n",
    "# get the symbolic outputs of each \"key\" layer (we gave them unique names).\n",
    "outputs_dict = dict([(layer.name, layer.output) for layer in model.layers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "=================================================================\n",
      "Total params: 20,024,384\n",
      "Trainable params: 20,024,384\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "70-vs_jZkKVc"
   },
   "source": [
    "# 4) En la siguientes celdas:\n",
    "\n",
    "- ¿Qué es la matriz de Gram?¿Para qué se usa?\n",
    "\n",
    "La matriz gram es la herramienta que se utiliza para medir la correlacion entre features, de esta forma puede diferenciarse el estilo del contenido.\n",
    "Es el producto interno entre los vectores de feature de una capa dada.\n",
    "\n",
    "Para calcular la matriz gram se debe tomar la representacion de una capa dada L y convertila en una matriz de dos dimensiones.\n",
    "Cada fila de dicha matriz esta compuesta de toda la salida de los filtros de la capa anterior. Siendo que cada filtro busca un feature en específico, podria decirse que cada fila de la matriz representa un feature dado en distintas posiciones de la imagen\n",
    "\n",
    "Para generar una textura que coincida con la de una imagen dada, se debe usar descenso por gradiente sobre la imagen de salida (imagen compuesta por ruido blaco unicamente), para encontrar otra imagen que corresponda con la representacion del estilo de la imagen origina (osea, los features de la imagen del estilo).\n",
    "Esto se hace minimizando el MSE entre las matrices de Gram de la imagen original y la imagen a ser generada.\n",
    "\n",
    "Para generar la imagen que combine el contenido de una imagen con el estilo de la otra, se intentan minizar en conjunto los MSE de las matrices de ambos componentes (MSE sobre matrices de gram para estilo y MSE regular para contenido), pesando cada uno de estos (contenido y estilo) para darles la preponderancia que se prefiera.\n",
    "\n",
    "- ¿Por qué se permutan las dimensiones de x?\n",
    "entiendo que esta primero poniendo la columna que corresponse al color, luego rows y luego columns. PREGUNTAR; ESTO NO ME QUEDA CLARO.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "K1FODPATvJ1k"
   },
   "outputs": [],
   "source": [
    "def gram_matrix(x):\n",
    "    features = K.batch_flatten(K.permute_dimensions(x, (2, 0, 1)))\n",
    "    gram = K.dot(features, K.transpose(features))\n",
    "    return gram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vBQkKFY0Rbx-"
   },
   "source": [
    "# 5) Losses:\n",
    "\n",
    "Explicar qué mide cada una de las losses en las siguientes tres celdas.\n",
    "\n",
    "Rta:\n",
    "\n",
    "*-style_loss:*\n",
    "\n",
    "Mide la loss del estilo, esto se calcula como la sumatoria de el MSE entre la matriz de gram de una imagen del estilo y la matriz de gram de la imagen generada, divido un valor en funcion de los cuadrados de la cantidad de canales y tamaño de la imagen.\n",
    "\n",
    "*-content_loss:*\n",
    "\n",
    "Mide el MSE del contenido a modificar (imagen output con rudio blanco) y la imagen dada como input sobre la cual se debe tomar el contenido.\n",
    "\n",
    "*-total_variation_loss:*\n",
    "\n",
    "PREGUNTAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "1-Gt0ahWvN6q"
   },
   "outputs": [],
   "source": [
    "def style_loss(style, combination):\n",
    "    assert K.ndim(style) == 3\n",
    "    assert K.ndim(combination) == 3\n",
    "    S = gram_matrix(style)\n",
    "    C = gram_matrix(combination)\n",
    "    channels = 3\n",
    "    size = img_nrows * img_ncols\n",
    "    return K.sum(K.square(S - C)) / (4.0 * (channels ** 2) * (size ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "XCqnju5RvQCo"
   },
   "outputs": [],
   "source": [
    "def content_loss(base, combination):\n",
    "    return K.sum(K.square(combination - base))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "udEp5h31vRnY"
   },
   "outputs": [],
   "source": [
    "def total_variation_loss(x):\n",
    "    assert K.ndim(x) == 4\n",
    "    a = K.square(\n",
    "        x[:, :img_nrows - 1, :img_ncols - 1, :] - x[:, 1:, :img_ncols - 1, :])\n",
    "    b = K.square(\n",
    "        x[:, :img_nrows - 1, :img_ncols - 1, :] - x[:, :img_nrows - 1, 1:, :])\n",
    "    return K.sum(K.pow(a + b, 1.25))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "-65vcinbvTZ0"
   },
   "outputs": [],
   "source": [
    "# Armamos la loss total\n",
    "loss = K.variable(0.0)\n",
    "layer_features = outputs_dict['block5_conv2']\n",
    "base_image_features = layer_features[0, :, :, :]\n",
    "combination_features = layer_features[2, :, :, :]\n",
    "loss = loss + content_weight * content_loss(base_image_features,\n",
    "                                            combination_features)\n",
    "\n",
    "feature_layers = ['block1_conv1', 'block2_conv1',\n",
    "                  'block3_conv1', 'block4_conv1',\n",
    "                  'block5_conv1']\n",
    "for layer_name in feature_layers:\n",
    "    layer_features = outputs_dict[layer_name]\n",
    "    style_reference_features = layer_features[1, :, :, :] \n",
    "    combination_features = layer_features[2, :, :, :]\n",
    "    sl = style_loss(style_reference_features, combination_features)\n",
    "    loss = loss + (style_weight / len(feature_layers)) * sl\n",
    "loss = loss + total_variation_weight * total_variation_loss(combination_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 92
    },
    "id": "pbz4n1OhvV2K",
    "outputId": "c2b208c6-7ddd-4a40-eeda-525f0809b963"
   },
   "outputs": [],
   "source": [
    "grads = K.gradients(loss, combination_image)\n",
    "\n",
    "outputs = [loss]\n",
    "if isinstance(grads, (list, tuple)):\n",
    "    outputs += grads\n",
    "else:\n",
    "    outputs.append(grads)\n",
    "\n",
    "f_outputs = K.function([combination_image], outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1JbydbOaVcvU"
   },
   "source": [
    "# 6) Explique el propósito de las siguientes tres celdas. ¿Qué hace la función fmin_l_bfgs_b? ¿En qué se diferencia con la implementación del paper? ¿Se puede utilizar alguna alternativa?\n",
    "\n",
    "Respuesta:\n",
    "\n",
    "*- Explicacion de las celdas:*\n",
    "\n",
    "eval_loss_and_grads es una funcion que obtiene tanto la loss como el gradiente que se definieron en las celdas anteriores.\n",
    "esta funcion es utilizada dentro del evaluator para obtener ambos valores (loss y gradient) y guardarlos en el mismo.\n",
    "Aunque estrictamente solo se necesite la loss en la funcion de loss, siendo que fmin_l_bfgs_b necesita dos funciones diferentes para loss y grad, se calculan ambos (loss y grad) en la funcion de loss y luego se guardan en el evaluator, para posteriormente poder devolver el gradiente en la funcion que corresponda.\n",
    "Calcular estos valores en dos funciones separadas seria ineficiente.\n",
    "\n",
    "la ultima celda instancia el evaluator, carga y preprocesa la imagen base que tiene el contenido y luego por cada una de las iteraciones esperadas (en nuestor caso 100) utiliza la funcion fmin_l_bfgs_b para poder ir minimizando la loss de la y aplicando el estilo.\n",
    "\n",
    "*- Funcion fmin_l_bfgs_b:*\n",
    "\n",
    "Es una funcion que busca minimizar una funcion pasada por parametro usando el algoritmo L-BFGS-B.\n",
    "en el uso que le damos, se le pasa la funcion de loss a minimizar, la imagen preprosesada y hecho un flatten para ser un array y la fprima que indica cual es el gradiente a obtener para minimizar la funcion.\n",
    "\n",
    "*- Diferencia con el paper:*\n",
    "\n",
    "- Se agrega total_variation_loss.\n",
    "- El ratio del pesaje de style vs content es diferente.\n",
    "- Solo se toma 1 capa convolucional para medir el MSE del content y no se intenta ver con cada una de las capaz, en nuestro caso solo tomamos la segunda capa convolucional del quinto bloque, en el paper hacen la prueba con la capa 1 de los 5 bloques. \n",
    "- VGG19 usa max pooling, en el paper se utilizó average pooling\n",
    "\n",
    "PREGUNTAR\n",
    "\n",
    "*- Alternativas:*\n",
    "\n",
    "QUE TIPO DE ALTARNATIVAS? OTRAS CNN? OTRAS TECNICAS? OTRA FORMA DE CALCULAR LOSS?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "zVE1_qemvZeN"
   },
   "outputs": [],
   "source": [
    "def eval_loss_and_grads(x):\n",
    "    x = x.reshape((1, img_nrows, img_ncols, 3))\n",
    "    outs = f_outputs([x])\n",
    "    loss_value = outs[0]\n",
    "    if len(outs[1:]) == 1:\n",
    "        grad_values = outs[1].flatten().astype('float64')\n",
    "    else:\n",
    "        grad_values = np.array(outs[1:]).flatten().astype('float64')\n",
    "    return loss_value, grad_values\n",
    "\n",
    "# this Evaluator class makes it possible\n",
    "# to compute loss and gradients in one pass\n",
    "# while retrieving them via two separate functions,\n",
    "# \"loss\" and \"grads\". This is done because scipy.optimize\n",
    "# requires separate functions for loss and gradients,\n",
    "# but computing them separately would be inefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "Qbl9roIgvdb1"
   },
   "outputs": [],
   "source": [
    "class Evaluator(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.loss_value = None\n",
    "        self.grads_values = None\n",
    "\n",
    "    def loss(self, x):\n",
    "        assert self.loss_value is None\n",
    "        loss_value, grad_values = eval_loss_and_grads(x)\n",
    "        self.loss_value = loss_value\n",
    "        self.grad_values = grad_values\n",
    "        return self.loss_value\n",
    "\n",
    "    def grads(self, x):\n",
    "        assert self.loss_value is not None\n",
    "        grad_values = np.copy(self.grad_values)\n",
    "        self.loss_value = None\n",
    "        self.grad_values = None\n",
    "        return grad_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sb0yOEl-WOE6"
   },
   "source": [
    "# 7) Ejecute la siguiente celda y observe las imágenes de salida en cada iteración."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "n31YBwCVvhAI",
    "outputId": "4c1bf03c-9d66-48ea-93f2-4489fc20beaa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of iteration 0\n",
      "Current loss value: 13274525000.0\n",
      "Image saved as content/output/output_at_iteration_0.png\n",
      "Iteration 0 completed in 241s\n",
      "Start of iteration 1\n",
      "Current loss value: 6374931000.0\n",
      "Image saved as content/output/output_at_iteration_1.png\n",
      "Iteration 1 completed in 246s\n",
      "Start of iteration 2\n",
      "Current loss value: 4389690000.0\n",
      "Image saved as content/output/output_at_iteration_2.png\n",
      "Iteration 2 completed in 267s\n",
      "Start of iteration 3\n",
      "Current loss value: 3366670000.0\n",
      "Image saved as content/output/output_at_iteration_3.png\n",
      "Iteration 3 completed in 262s\n",
      "Start of iteration 4\n",
      "Current loss value: 2870151700.0\n",
      "Image saved as content/output/output_at_iteration_4.png\n",
      "Iteration 4 completed in 252s\n",
      "Start of iteration 5\n",
      "Current loss value: 2258674400.0\n",
      "Image saved as content/output/output_at_iteration_5.png\n",
      "Iteration 5 completed in 258s\n",
      "Start of iteration 6\n",
      "Current loss value: 1967804000.0\n",
      "Image saved as content/output/output_at_iteration_6.png\n",
      "Iteration 6 completed in 259s\n",
      "Start of iteration 7\n",
      "Current loss value: 1842716200.0\n",
      "Image saved as content/output/output_at_iteration_7.png\n",
      "Iteration 7 completed in 254s\n",
      "Start of iteration 8\n",
      "Current loss value: 1756735500.0\n",
      "Image saved as content/output/output_at_iteration_8.png\n",
      "Iteration 8 completed in 252s\n",
      "Start of iteration 9\n",
      "Current loss value: 1607749600.0\n",
      "Image saved as content/output/output_at_iteration_9.png\n",
      "Iteration 9 completed in 249s\n",
      "Start of iteration 10\n",
      "Current loss value: 1528115200.0\n",
      "Image saved as content/output/output_at_iteration_10.png\n",
      "Iteration 10 completed in 256s\n",
      "Start of iteration 11\n",
      "Current loss value: 1465660700.0\n",
      "Image saved as content/output/output_at_iteration_11.png\n",
      "Iteration 11 completed in 256s\n",
      "Start of iteration 12\n",
      "Current loss value: 1415467800.0\n",
      "Image saved as content/output/output_at_iteration_12.png\n",
      "Iteration 12 completed in 262s\n",
      "Start of iteration 13\n",
      "Current loss value: 1380083300.0\n",
      "Image saved as content/output/output_at_iteration_13.png\n",
      "Iteration 13 completed in 251s\n",
      "Start of iteration 14\n",
      "Current loss value: 1352523900.0\n",
      "Image saved as content/output/output_at_iteration_14.png\n",
      "Iteration 14 completed in 259s\n",
      "Start of iteration 15\n",
      "Current loss value: 1329806100.0\n",
      "Image saved as content/output/output_at_iteration_15.png\n",
      "Iteration 15 completed in 248s\n",
      "Start of iteration 16\n",
      "Current loss value: 1300557800.0\n",
      "Image saved as content/output/output_at_iteration_16.png\n",
      "Iteration 16 completed in 243s\n",
      "Start of iteration 17\n",
      "Current loss value: 1271648800.0\n",
      "Image saved as content/output/output_at_iteration_17.png\n",
      "Iteration 17 completed in 2318s\n",
      "Start of iteration 18\n",
      "Current loss value: 1247775500.0\n",
      "Image saved as content/output/output_at_iteration_18.png\n",
      "Iteration 18 completed in 2256s\n",
      "Start of iteration 19\n",
      "Current loss value: 1231819800.0\n",
      "Image saved as content/output/output_at_iteration_19.png\n",
      "Iteration 19 completed in 229s\n",
      "Start of iteration 20\n",
      "Current loss value: 1217332700.0\n",
      "Image saved as content/output/output_at_iteration_20.png\n",
      "Iteration 20 completed in 234s\n",
      "Start of iteration 21\n",
      "Current loss value: 1195598600.0\n",
      "Image saved as content/output/output_at_iteration_21.png\n",
      "Iteration 21 completed in 780s\n",
      "Start of iteration 22\n",
      "Current loss value: 1178302800.0\n",
      "Image saved as content/output/output_at_iteration_22.png\n",
      "Iteration 22 completed in 237s\n",
      "Start of iteration 23\n",
      "Current loss value: 1164046000.0\n",
      "Image saved as content/output/output_at_iteration_23.png\n",
      "Iteration 23 completed in 239s\n",
      "Start of iteration 24\n",
      "Current loss value: 1151654700.0\n",
      "Image saved as content/output/output_at_iteration_24.png\n",
      "Iteration 24 completed in 514s\n",
      "Start of iteration 25\n",
      "Current loss value: 1138555900.0\n",
      "Image saved as content/output/output_at_iteration_25.png\n",
      "Iteration 25 completed in 240s\n",
      "Start of iteration 26\n",
      "Current loss value: 1126897800.0\n",
      "Image saved as content/output/output_at_iteration_26.png\n",
      "Iteration 26 completed in 245s\n",
      "Start of iteration 27\n",
      "Current loss value: 1118794400.0\n",
      "Image saved as content/output/output_at_iteration_27.png\n",
      "Iteration 27 completed in 2329s\n",
      "Start of iteration 28\n",
      "Current loss value: 1111996900.0\n",
      "Image saved as content/output/output_at_iteration_28.png\n",
      "Iteration 28 completed in 290s\n",
      "Start of iteration 29\n",
      "Current loss value: 1104335600.0\n",
      "Image saved as content/output/output_at_iteration_29.png\n",
      "Iteration 29 completed in 289s\n",
      "Start of iteration 30\n",
      "Current loss value: 1097590800.0\n",
      "Image saved as content/output/output_at_iteration_30.png\n",
      "Iteration 30 completed in 293s\n",
      "Start of iteration 31\n",
      "Current loss value: 1091293600.0\n",
      "Image saved as content/output/output_at_iteration_31.png\n",
      "Iteration 31 completed in 289s\n",
      "Start of iteration 32\n",
      "Current loss value: 1085276300.0\n",
      "Image saved as content/output/output_at_iteration_32.png\n",
      "Iteration 32 completed in 260s\n",
      "Start of iteration 33\n",
      "Current loss value: 1079950200.0\n",
      "Image saved as content/output/output_at_iteration_33.png\n",
      "Iteration 33 completed in 250s\n",
      "Start of iteration 34\n",
      "Current loss value: 1074459100.0\n",
      "Image saved as content/output/output_at_iteration_34.png\n",
      "Iteration 34 completed in 250s\n",
      "Start of iteration 35\n",
      "Current loss value: 1068371100.0\n",
      "Image saved as content/output/output_at_iteration_35.png\n",
      "Iteration 35 completed in 249s\n",
      "Start of iteration 36\n",
      "Current loss value: 1062985500.0\n",
      "Image saved as content/output/output_at_iteration_36.png\n",
      "Iteration 36 completed in 248s\n",
      "Start of iteration 37\n",
      "Current loss value: 1057727100.0\n",
      "Image saved as content/output/output_at_iteration_37.png\n",
      "Iteration 37 completed in 247s\n",
      "Start of iteration 38\n",
      "Current loss value: 1053508000.0\n",
      "Image saved as content/output/output_at_iteration_38.png\n",
      "Iteration 38 completed in 409s\n",
      "Start of iteration 39\n",
      "Current loss value: 1048750700.0\n",
      "Image saved as content/output/output_at_iteration_39.png\n",
      "Iteration 39 completed in 245s\n",
      "Start of iteration 40\n",
      "Current loss value: 1044420200.0\n",
      "Image saved as content/output/output_at_iteration_40.png\n",
      "Iteration 40 completed in 748s\n",
      "Start of iteration 41\n",
      "Current loss value: 1040471040.0\n",
      "Image saved as content/output/output_at_iteration_41.png\n",
      "Iteration 41 completed in 234s\n",
      "Start of iteration 42\n",
      "Current loss value: 1036734850.0\n",
      "Image saved as content/output/output_at_iteration_42.png\n",
      "Iteration 42 completed in 248s\n",
      "Start of iteration 43\n",
      "Current loss value: 1031658750.0\n",
      "Image saved as content/output/output_at_iteration_43.png\n",
      "Iteration 43 completed in 247s\n",
      "Start of iteration 44\n",
      "Current loss value: 1027484400.0\n",
      "Image saved as content/output/output_at_iteration_44.png\n",
      "Iteration 44 completed in 246s\n",
      "Start of iteration 45\n",
      "Current loss value: 1022658400.0\n",
      "Image saved as content/output/output_at_iteration_45.png\n",
      "Iteration 45 completed in 442s\n",
      "Start of iteration 46\n",
      "Current loss value: 1018426400.0\n",
      "Image saved as content/output/output_at_iteration_46.png\n",
      "Iteration 46 completed in 828s\n",
      "Start of iteration 47\n",
      "Current loss value: 1012663360.0\n",
      "Image saved as content/output/output_at_iteration_47.png\n",
      "Iteration 47 completed in 247s\n",
      "Start of iteration 48\n",
      "Current loss value: 1007910500.0\n",
      "Image saved as content/output/output_at_iteration_48.png\n",
      "Iteration 48 completed in 255s\n",
      "Start of iteration 49\n",
      "Current loss value: 1003729800.0\n",
      "Image saved as content/output/output_at_iteration_49.png\n",
      "Iteration 49 completed in 297s\n",
      "Start of iteration 50\n",
      "Current loss value: 999299100.0\n",
      "Image saved as content/output/output_at_iteration_50.png\n",
      "Iteration 50 completed in 300s\n",
      "Start of iteration 51\n",
      "Current loss value: 996806850.0\n",
      "Image saved as content/output/output_at_iteration_51.png\n",
      "Iteration 51 completed in 299s\n",
      "Start of iteration 52\n",
      "Current loss value: 994372000.0\n",
      "Image saved as content/output/output_at_iteration_52.png\n",
      "Iteration 52 completed in 302s\n",
      "Start of iteration 53\n",
      "Current loss value: 990151700.0\n",
      "Image saved as content/output/output_at_iteration_53.png\n",
      "Iteration 53 completed in 301s\n",
      "Start of iteration 54\n",
      "Current loss value: 984402940.0\n",
      "Image saved as content/output/output_at_iteration_54.png\n",
      "Iteration 54 completed in 287s\n",
      "Start of iteration 55\n",
      "Current loss value: 981378700.0\n",
      "Image saved as content/output/output_at_iteration_55.png\n",
      "Iteration 55 completed in 256s\n",
      "Start of iteration 56\n",
      "Current loss value: 978764400.0\n",
      "Image saved as content/output/output_at_iteration_56.png\n",
      "Iteration 56 completed in 258s\n",
      "Start of iteration 57\n",
      "Current loss value: 976695550.0\n",
      "Image saved as content/output/output_at_iteration_57.png\n",
      "Iteration 57 completed in 263s\n",
      "Start of iteration 58\n",
      "Current loss value: 974544000.0\n",
      "Image saved as content/output/output_at_iteration_58.png\n",
      "Iteration 58 completed in 257s\n",
      "Start of iteration 59\n",
      "Current loss value: 972235600.0\n",
      "Image saved as content/output/output_at_iteration_59.png\n",
      "Iteration 59 completed in 253s\n",
      "Start of iteration 60\n",
      "Current loss value: 969879700.0\n",
      "Image saved as content/output/output_at_iteration_60.png\n",
      "Iteration 60 completed in 256s\n",
      "Start of iteration 61\n",
      "Current loss value: 968136060.0\n",
      "Image saved as content/output/output_at_iteration_61.png\n",
      "Iteration 61 completed in 259s\n",
      "Start of iteration 62\n",
      "Current loss value: 966227260.0\n",
      "Image saved as content/output/output_at_iteration_62.png\n",
      "Iteration 62 completed in 263s\n",
      "Start of iteration 63\n",
      "Current loss value: 964198900.0\n",
      "Image saved as content/output/output_at_iteration_63.png\n",
      "Iteration 63 completed in 260s\n",
      "Start of iteration 64\n",
      "Current loss value: 962361500.0\n",
      "Image saved as content/output/output_at_iteration_64.png\n",
      "Iteration 64 completed in 258s\n",
      "Start of iteration 65\n",
      "Current loss value: 960103550.0\n",
      "Image saved as content/output/output_at_iteration_65.png\n",
      "Iteration 65 completed in 247s\n",
      "Start of iteration 66\n",
      "Current loss value: 957907200.0\n",
      "Image saved as content/output/output_at_iteration_66.png\n",
      "Iteration 66 completed in 286s\n",
      "Start of iteration 67\n",
      "Current loss value: 955781600.0\n",
      "Image saved as content/output/output_at_iteration_67.png\n",
      "Iteration 67 completed in 263s\n",
      "Start of iteration 68\n",
      "Current loss value: 953730400.0\n",
      "Image saved as content/output/output_at_iteration_68.png\n",
      "Iteration 68 completed in 250s\n",
      "Start of iteration 69\n",
      "Current loss value: 952324100.0\n",
      "Image saved as content/output/output_at_iteration_69.png\n",
      "Iteration 69 completed in 254s\n",
      "Start of iteration 70\n",
      "Current loss value: 950724860.0\n",
      "Image saved as content/output/output_at_iteration_70.png\n",
      "Iteration 70 completed in 267s\n",
      "Start of iteration 71\n",
      "Current loss value: 949164860.0\n",
      "Image saved as content/output/output_at_iteration_71.png\n",
      "Iteration 71 completed in 264s\n",
      "Start of iteration 72\n",
      "Current loss value: 947752600.0\n",
      "Image saved as content/output/output_at_iteration_72.png\n",
      "Iteration 72 completed in 260s\n",
      "Start of iteration 73\n",
      "Current loss value: 946448800.0\n",
      "Image saved as content/output/output_at_iteration_73.png\n",
      "Iteration 73 completed in 255s\n",
      "Start of iteration 74\n",
      "Current loss value: 944809700.0\n",
      "Image saved as content/output/output_at_iteration_74.png\n",
      "Iteration 74 completed in 255s\n",
      "Start of iteration 75\n",
      "Current loss value: 943246700.0\n",
      "Image saved as content/output/output_at_iteration_75.png\n",
      "Iteration 75 completed in 259s\n",
      "Start of iteration 76\n",
      "Current loss value: 941259100.0\n",
      "Image saved as content/output/output_at_iteration_76.png\n",
      "Iteration 76 completed in 261s\n",
      "Start of iteration 77\n",
      "Current loss value: 939216800.0\n",
      "Image saved as content/output/output_at_iteration_77.png\n",
      "Iteration 77 completed in 259s\n",
      "Start of iteration 78\n",
      "Current loss value: 937593860.0\n",
      "Image saved as content/output/output_at_iteration_78.png\n",
      "Iteration 78 completed in 260s\n",
      "Start of iteration 79\n",
      "Current loss value: 935989250.0\n",
      "Image saved as content/output/output_at_iteration_79.png\n",
      "Iteration 79 completed in 271s\n",
      "Start of iteration 80\n",
      "Current loss value: 934308600.0\n",
      "Image saved as content/output/output_at_iteration_80.png\n",
      "Iteration 80 completed in 261s\n",
      "Start of iteration 81\n",
      "Current loss value: 932838900.0\n",
      "Image saved as content/output/output_at_iteration_81.png\n",
      "Iteration 81 completed in 258s\n",
      "Start of iteration 82\n",
      "Current loss value: 931021440.0\n",
      "Image saved as content/output/output_at_iteration_82.png\n",
      "Iteration 82 completed in 258s\n",
      "Start of iteration 83\n",
      "Current loss value: 929209340.0\n",
      "Image saved as content/output/output_at_iteration_83.png\n",
      "Iteration 83 completed in 265s\n",
      "Start of iteration 84\n",
      "Current loss value: 927644160.0\n",
      "Image saved as content/output/output_at_iteration_84.png\n",
      "Iteration 84 completed in 259s\n",
      "Start of iteration 85\n",
      "Current loss value: 925997300.0\n",
      "Image saved as content/output/output_at_iteration_85.png\n",
      "Iteration 85 completed in 259s\n",
      "Start of iteration 86\n",
      "Current loss value: 924613900.0\n",
      "Image saved as content/output/output_at_iteration_86.png\n",
      "Iteration 86 completed in 258s\n",
      "Start of iteration 87\n",
      "Current loss value: 923325400.0\n",
      "Image saved as content/output/output_at_iteration_87.png\n",
      "Iteration 87 completed in 261s\n",
      "Start of iteration 88\n",
      "Current loss value: 922354240.0\n",
      "Image saved as content/output/output_at_iteration_88.png\n",
      "Iteration 88 completed in 259s\n",
      "Start of iteration 89\n",
      "Current loss value: 921189000.0\n",
      "Image saved as content/output/output_at_iteration_89.png\n",
      "Iteration 89 completed in 245s\n",
      "Start of iteration 90\n",
      "Current loss value: 920144000.0\n",
      "Image saved as content/output/output_at_iteration_90.png\n",
      "Iteration 90 completed in 244s\n",
      "Start of iteration 91\n",
      "Current loss value: 919155300.0\n",
      "Image saved as content/output/output_at_iteration_91.png\n",
      "Iteration 91 completed in 243s\n",
      "Start of iteration 92\n",
      "Current loss value: 917886200.0\n",
      "Image saved as content/output/output_at_iteration_92.png\n",
      "Iteration 92 completed in 244s\n",
      "Start of iteration 93\n",
      "Current loss value: 916810240.0\n",
      "Image saved as content/output/output_at_iteration_93.png\n",
      "Iteration 93 completed in 244s\n",
      "Start of iteration 94\n",
      "Current loss value: 915969400.0\n",
      "Image saved as content/output/output_at_iteration_94.png\n",
      "Iteration 94 completed in 243s\n",
      "Start of iteration 95\n",
      "Current loss value: 915028100.0\n",
      "Image saved as content/output/output_at_iteration_95.png\n",
      "Iteration 95 completed in 4794s\n",
      "Start of iteration 96\n",
      "Current loss value: 913787140.0\n",
      "Image saved as content/output/output_at_iteration_96.png\n",
      "Iteration 96 completed in 237s\n",
      "Start of iteration 97\n",
      "Current loss value: 912344100.0\n",
      "Image saved as content/output/output_at_iteration_97.png\n",
      "Iteration 97 completed in 244s\n",
      "Start of iteration 98\n",
      "Current loss value: 911185000.0\n",
      "Image saved as content/output/output_at_iteration_98.png\n",
      "Iteration 98 completed in 253s\n",
      "Start of iteration 99\n",
      "Current loss value: 910010300.0\n",
      "Image saved as content/output/output_at_iteration_99.png\n",
      "Iteration 99 completed in 252s\n"
     ]
    }
   ],
   "source": [
    "evaluator = Evaluator()\n",
    "\n",
    "# run scipy-based optimization (L-BFGS) over the pixels of the generated image\n",
    "# so as to minimize the neural style loss\n",
    "x = preprocess_image(base_image_path)\n",
    "\n",
    "for i in range(iterations):\n",
    "    print('Start of iteration', i)\n",
    "    start_time = time.time()\n",
    "    x, min_val, info = fmin_l_bfgs_b(evaluator.loss, x.flatten(),\n",
    "                                     fprime=evaluator.grads, maxfun=20)\n",
    "    print('Current loss value:', min_val)\n",
    "    # save current generated image\n",
    "    img = deprocess_image(x.copy())\n",
    "    fname = result_prefix / ('output_at_iteration_%d.png' % i)\n",
    "    save_img(fname, img)\n",
    "    end_time = time.time()\n",
    "    print('Image saved as', fname)\n",
    "    print('Iteration %d completed in %ds' % (i, end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SkiJtofbWWy1"
   },
   "source": [
    "# 8) Generar imágenes para distintas combinaciones de pesos de las losses. Explicar las diferencias. (Adjuntar las imágenes generadas como archivos separados.)\n",
    "\n",
    "Respuesta:\n",
    "\n",
    "# 9) Cambiar las imágenes de contenido y estilo por unas elegidas por usted. Adjuntar el resultado.\n",
    "\n",
    "Respuesta:"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Trabajo Final CNN - Style Transfer.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
